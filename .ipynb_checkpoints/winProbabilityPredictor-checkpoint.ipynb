{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4466312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import json\n",
    "\n",
    "# Function to read .xz archives from ESTA\n",
    "def read_parsed_demo(filename):\n",
    "  with lzma.LZMAFile(filename, \"rb\") as f:\n",
    "    d = json.load(f)\n",
    "    return d\n",
    "\n",
    "def generate_vector_state(frame, map_name):\n",
    "    \"\"\"Returns a game state in a dictionary format.\n",
    "\n",
    "    Args:\n",
    "        frame (dict) : Dict output of a frame generated from the DemoParser class\n",
    "        map_name (string): String indicating the map name\n",
    "\n",
    "    Returns:\n",
    "        A dict with keys for each feature.\n",
    "    \"\"\"\n",
    "    game_state = {}\n",
    "    game_state[\"mapName\"] = map_name\n",
    "    game_state[\"secondsSincePhaseStart\"] = frame[\"seconds\"]\n",
    "    game_state[\"bombPlanted\"] = frame[\"bombPlanted\"]\n",
    "    game_state[\"bombsite\"] = frame[\"bombsite\"]\n",
    "    game_state[\"totalSmokes\"] = len(frame[\"smokes\"])\n",
    "    game_state[\"totalFires\"] = len(frame[\"fires\"])\n",
    "\n",
    "    # Team specific info (CT)\n",
    "    game_state[\"ctAlive\"] = 0\n",
    "    game_state[\"ctHp\"] = 0\n",
    "    game_state[\"ctArmor\"] = 0\n",
    "    game_state[\"ctHelmet\"] = 0\n",
    "    game_state[\"ctEq\"] = 0\n",
    "    game_state[\"ctUtility\"] = 0\n",
    "    game_state[\"ctEqValStart\"] = 0\n",
    "    game_state[\"ctBombZone\"] = 0\n",
    "    game_state[\"defusers\"] = 0\n",
    "    for p in frame[\"ct\"][\"players\"]:\n",
    "        game_state[\"ctEqValStart\"] += p[\"equipmentValueFreezetimeEnd\"]\n",
    "        if p[\"isAlive\"]:\n",
    "            game_state[\"ctAlive\"] += 1\n",
    "            game_state[\"ctHp\"] += p[\"hp\"]\n",
    "            game_state[\"ctArmor\"] += p[\"armor\"]\n",
    "            game_state[\"ctHelmet\"] += p[\"hasHelmet\"]\n",
    "            game_state[\"ctEq\"] += p[\"equipmentValue\"]\n",
    "            game_state[\"ctUtility\"] += p[\"totalUtility\"]\n",
    "            game_state[\"defusers\"] += p[\"hasDefuse\"]\n",
    "            if p[\"isInBombZone\"]:\n",
    "                game_state[\"ctBombZone\"] += 1\n",
    "\n",
    "    # Team specific info (T)\n",
    "    game_state[\"tAlive\"] = 0\n",
    "    game_state[\"tHp\"] = 0\n",
    "    game_state[\"tArmor\"] = 0\n",
    "    game_state[\"tHelmet\"] = 0\n",
    "    game_state[\"tEq\"] = 0\n",
    "    game_state[\"tUtility\"] = 0\n",
    "    game_state[\"tEqValStart\"] = 0\n",
    "    game_state[\"tHoldingBomb\"] = 0\n",
    "    game_state[\"tBombZone\"] = 0\n",
    "    for p in frame[\"t\"][\"players\"]:\n",
    "        game_state[\"tEqValStart\"] += p[\"equipmentValueFreezetimeEnd\"]\n",
    "        if p[\"isAlive\"]:\n",
    "            game_state[\"tAlive\"] += 1\n",
    "            game_state[\"tHp\"] += p[\"hp\"]\n",
    "            game_state[\"tArmor\"] += p[\"armor\"]\n",
    "            game_state[\"tHelmet\"] += p[\"hasHelmet\"]\n",
    "            game_state[\"tEq\"] += p[\"equipmentValue\"]\n",
    "            game_state[\"tUtility\"] += p[\"totalUtility\"]\n",
    "            if p[\"isInBombZone\"]:\n",
    "                game_state[\"tBombZone\"] += 1\n",
    "            if p[\"hasBomb\"]:\n",
    "                game_state[\"tHoldingBomb\"] = 1\n",
    "\n",
    "    return game_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f7107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "online_files = os.listdir(\"C:\\\\Users\\\\Matias\\\\esta\\\\data\\\\online\")\n",
    "online_files = [\"C:\\\\Users\\\\Matias\\\\esta\\\\data\\\\online\\\\\" + f for f in online_files] \n",
    "\n",
    "#demo_files = online_files + lan_files\n",
    "demo_files = online_files\n",
    "\n",
    "parsed_demos = {}\n",
    "\n",
    "for f in tqdm(demo_files):\n",
    "  demo = read_parsed_demo(f)\n",
    "\n",
    "  parsed_demos[demo[\"demoId\"]] = []\n",
    "\n",
    "  for r in demo[\"gameRounds\"]:\n",
    "    parsed_frames_df_round = []\n",
    "    ct_win = 1\n",
    "\n",
    "    if r[\"roundEndReason\"] in [\"CTWin\", \"TargetSaved\", \"BombDefused\", \"TargetBombed\", \"TerroristsWin\"]:\n",
    "      if r[\"roundEndReason\"] not in [\"CTWin\", \"TargetSaved\", \"BombDefused\"]:\n",
    "        ct_win = 0\n",
    "      for fr in r[\"frames\"]:\n",
    "        if (fr[\"ct\"][\"players\"] is not None) & (fr[\"t\"][\"players\"] is not None) & (fr[\"clockTime\"] != \"00:00\") & (fr[\"t\"][\"alivePlayers\"] >= 0) & (fr[\"ct\"][\"alivePlayers\"] >= 1):\n",
    "          if (len(fr[\"ct\"][\"players\"]) == 5) & (len(fr[\"t\"][\"players\"]) == 5):\n",
    "            # Create dataframe\n",
    "            frame_row = generate_vector_state(fr, demo[\"mapName\"])\n",
    "            frame_row[\"ctWin\"] = ct_win\n",
    "            frame_row[\"mapName\"] = demo[\"mapName\"]         \n",
    "            \n",
    "            parsed_frames_df_round.append(frame_row)\n",
    "\n",
    "    parsed_demos[demo[\"demoId\"]].append(parsed_frames_df_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811ca007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "all_states = []\n",
    "\n",
    "for demo in tqdm(parsed_demos.keys()):\n",
    "  for r in parsed_demos[demo]:\n",
    "    if len(r) > 0:\n",
    "      total_frames = len(r)\n",
    "      indices = random.sample(range(0, total_frames), 1)\n",
    "      all_states.append(r[indices[0]])\n",
    "\n",
    "import pandas as pd\n",
    "all_df = pd.DataFrame(all_states)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_size=0.7\n",
    "\n",
    "X = all_df.drop(\"ctWin\", axis=1).copy()\n",
    "y = all_df[\"ctWin\"]\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.7)\n",
    "\n",
    "test_size = 0.5\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem,y_rem, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303302b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "X_train[\"bombPlanted\"] = X_train[\"bombPlanted\"].astype(\"category\")\n",
    "X_train[\"bombsite\"] = X_train[\"bombsite\"].astype(\"category\")\n",
    "X_train[\"mapName\"] = X_train[\"mapName\"].astype(\"category\")\n",
    "X_val[\"bombPlanted\"] = X_val[\"bombPlanted\"].astype(\"category\")\n",
    "X_val[\"bombsite\"] = X_val[\"bombsite\"].astype(\"category\")\n",
    "X_val[\"mapName\"] = X_val[\"mapName\"].astype(\"category\")\n",
    "X_test[\"bombPlanted\"] = X_test[\"bombPlanted\"].astype(\"category\")\n",
    "X_test[\"bombsite\"] = X_test[\"bombsite\"].astype(\"category\")\n",
    "X_test[\"mapName\"] = X_test[\"mapName\"].astype(\"category\")\n",
    "\n",
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "xgb = XGBClassifier(tree_method=\"gpu_hist\", enable_categorical=True)\n",
    "xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=50, verbose=False)\n",
    "\n",
    "cb = CatBoostClassifier(task_type=\"GPU\", devices='0:1', verbose=False)\n",
    "cb.fit(X_train, y_train, eval_set=[(X_val, y_val)], cat_features=[0,2,3], early_stopping_rounds=50)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e010ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Guardo el modelo entrenado\n",
    "pickle.dump(lgbm, open('lgbm.pkl', 'wb'))\n",
    "pickle.dump(xgb, open(\"xgb.pkl\", 'wb'))\n",
    "pickle.dump(cb, open(\"cb.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c90bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "preds_lgbm = lgbm.predict_proba(X_test)\n",
    "preds_xgb = xgb.predict_proba(X_test)\n",
    "preds_cb = cb.predict_proba(X_test)\n",
    "\n",
    "lgbm_ll = log_loss(y_test, preds_lgbm[:,1])\n",
    "xgb_ll = log_loss(y_test, preds_xgb[:,1])\n",
    "cb_ll = log_loss(y_test, preds_cb[:,1])\n",
    "\n",
    "print(\"{} LGBM, {} XGB, {} CB\".format(lgbm_ll, xgb_ll, cb_ll))\n",
    "\n",
    "cb.save_model(\"win_prob.cb\")\n",
    "\n",
    "for a, b in zip(X_train.columns, cb.feature_importances_):\n",
    "  print(\"{}, {}\".format(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438b89d",
   "metadata": {},
   "source": [
    "A partir de acá se corre directamente para calcular la probabilidad de ganar cada ronda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9833c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\Matias\\\\Documents\\\\UDESA\\\\Tesis_maestria\\\\Atpt\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cabf413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patool: Extracting DreamHack-Open-Fall-2020-oct24-astralis-vs-heroic-bo3-2.rar ...\n",
      "patool: running \"C:\\Program Files\\WinRAR\\rar.EXE\" x -- C:\\Users\\Matias\\Documents\\UDESA\\Tesis_maestria\\Atpt\\winProbDemos\\DreamHack-Open-Fall-2020-oct24-astralis-vs-heroic-bo3-2.rar\n",
      "patool:     with cwd=C:\\Users\\Matias\\Documents\\UDESA\\Tesis_maestria\\Atpt\\winProbDemos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error calling Go. Check if Go is installed using 'go version'. Need at least v1.17.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patool: ... DreamHack-Open-Fall-2020-oct24-astralis-vs-heroic-bo3-2.rar extracted to `C:\\Users\\Matias\\Documents\\UDESA\\Tesis_maestria\\Atpt\\winProbDemos'.\n",
      "[WinError 2] The system cannot find the file specified\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error calling Go. Check if Go is installed using 'go version'. Need at least v1.17.0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 46>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m demo_parser \u001b[38;5;241m=\u001b[39m DemoParser(\n\u001b[0;32m     48\u001b[0m demofile \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m demo,\n\u001b[0;32m     49\u001b[0m parse_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, \n\u001b[0;32m     50\u001b[0m buy_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhltv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Parse the demofile, output results to dictionary\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdemo_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Agarro los frames del comienzo de cada ronda\u001b[39;00m\n\u001b[0;32m     58\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\awpy\\parser\\demoparser.py:237\u001b[0m, in \u001b[0;36mDemoParser.parse\u001b[1;34m(self, return_type, clean)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m, clean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;124;03m\"\"\"Wrapper for parse_demo() and read_json(). Use to parse a demo.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m        AttributeError: Raises an AttributeError if the .json attribute is None\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_demo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_json(json_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutpath \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_file)\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clean:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\awpy\\parser\\demoparser.py:142\u001b[0m, in \u001b[0;36mDemoParser.parse_demo\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m acceptable_go:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError calling Go. Check if Go is installed using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgo version\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Need at least v1.17.0.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m     )\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError calling Go. Check if Go is installed using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgo version\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Need at least v1.17.0.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGo version>=1.17.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Error calling Go. Check if Go is installed using 'go version'. Need at least v1.17.0."
     ]
    }
   ],
   "source": [
    "from openpyxl import Workbook\n",
    "from awpy.parser import DemoParser\n",
    "import pandas as pd\n",
    "import os\n",
    "import patoolib\n",
    "import pickle\n",
    "\n",
    "# Abro el modelo entrenado\n",
    "#lgbm  = pickle.load(open('lgbm.pkl','rb'))\n",
    "\n",
    "# lista de demos a procesar\n",
    "path = \"C:\\\\Users\\\\Matias\\\\Documents\\\\UDESA\\\\Tesis_maestria\\\\Atpt\\\\winProbDemos\"\n",
    "os.chdir(path)\n",
    "\n",
    "carpetas = []\n",
    "for file in os.listdir():\n",
    "    if \".rar\" in file:\n",
    "        carpetas += [file]\n",
    "    elif \".dem\" in file or \".json\" in file:\n",
    "        os.remove(file)\n",
    "        \n",
    "    \n",
    "# Ahora hay más archivos, puedo iterar sobre los nuevos\n",
    "for folder in carpetas:\n",
    "    # Extraigo la carpeta\n",
    "    patoolib.extract_archive(\"%s\" % folder, outdir=\"%s\" %path)\n",
    "    # La muevo a parsedDemos\n",
    "    #shutil.move(path + \"\\\\\" + folder, \"C:\\\\Users\\\\Matias\\\\Documents\\\\UDESA\\\\Tesis_maestria\\\\Atpt\\\\parsedDemos\")\n",
    "    \n",
    "    # Itero sobre los files y me fijo si son demo y no les cambié el nombre. Si no, les cambio el nombre\n",
    "    for demo in os.listdir():\n",
    "        for nombre in carpetas:\n",
    "            if (\".dem\" not in demo) or (demo[0] == \"x\"):\n",
    "                break\n",
    "        else:\n",
    "            os.rename(demo, \"x\" + folder.split(\"vs\")[0] + \"vs\" + demo.split(\"vs\")[1])\n",
    "\n",
    "# Agarro los nombres de las demos\n",
    "demos = []\n",
    "for file in os.listdir():\n",
    "    if \".dem\" in file:\n",
    "        demos += [file]\n",
    "\n",
    "### Itero el parser por cada demo\n",
    "round_state_df = pd.DataFrame()\n",
    "for demo in demos:\n",
    "    demo_parser = DemoParser(\n",
    "    demofile = \"%s\" % demo,\n",
    "    parse_rate=128, \n",
    "    buy_style=\"hltv\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Parse the demofile, output results to dictionary\n",
    "    df = demo_parser.parse(return_type=\"json\")\n",
    "\n",
    "    # Agarro los frames del comienzo de cada ronda\n",
    "    frames = []\n",
    "    for ronda in df[\"gameRounds\"]:\n",
    "        for f in ronda[\"frames\"]:\n",
    "            if f[\"seconds\"] == max(f[\"seconds\"]):\n",
    "                frames.append(f)\n",
    "                break\n",
    "    mapa = df[\"mapName\"]\n",
    "    \n",
    "\n",
    "    # Genero los vectores para cada frame y los paso a un dataframe\n",
    "    states = []\n",
    "    for f in frames:\n",
    "        game_state = generate_vector_state(f, mapa)\n",
    "        states.append(game_state)\n",
    "    states = pd.DataFrame(states)\n",
    "    states[\"matchID\"] = (demo[:-4])\n",
    "    #states.index += 1\n",
    "    round_state_df = pd.concat([round_state_df, pd.DataFrame(states)])\n",
    "\n",
    "round_state_df_2 = round_state_df.drop(round_state_df.columns[len(round_state_df.columns)-1], axis=1)\n",
    "round_state_df_2\n",
    "round_state_df_2[\"bombPlanted\"] = round_state_df_2[\"bombPlanted\"].astype(\"category\")\n",
    "round_state_df_2[\"bombsite\"] = round_state_df_2[\"bombsite\"].astype(\"category\")\n",
    "round_state_df_2[\"mapName\"] = round_state_df_2[\"mapName\"].astype(\"category\")\n",
    "\n",
    "round_state_df.reset_index(inplace = True)\n",
    "\n",
    "dfWinProbLgbm = pd.DataFrame(lgbm.predict_proba(pd.DataFrame(round_state_df_2)), columns = [\"tWinProbLgbm\", \"ctWinProbLgbm\"])\n",
    "dfWinProbXgb = pd.DataFrame(xgb.predict_proba(pd.DataFrame(round_state_df_2)), columns = [\"tWinProbXgb\", \"ctWinProbXgb\"])\n",
    "dfWinProbCb = pd.DataFrame(cb.predict_proba(pd.DataFrame(round_state_df_2)), columns = [\"tWinProbCb\", \"ctWinProbCb\"])\n",
    "\n",
    "round_state_df[[\"tWinProbLgbm\", \"ctWinProbLgbm\"]] = dfWinProbLgbm\n",
    "round_state_df[[\"tWinProbXgb\", \"ctWinProbXgb\"]] = dfWinProbXgb\n",
    "round_state_df[[\"tWinProbCb\", \"ctWinProbCb\"]] = dfWinProbCb\n",
    "\n",
    "with pd.ExcelWriter(\n",
    "    \"C:\\\\Users\\\\Matias\\\\Documents\\\\UDESA\\\\Tesis_maestria\\\\Atpt\\\\winProb.xlsx\",\n",
    "    mode = \"a\",\n",
    "    if_sheet_exists = \"overlay\"\n",
    ") as writer:\n",
    "    round_state_df.to_excel(writer, index = False, startrow = writer.sheets['Sheet1'].max_row, header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dea65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from awpy.parser import DemoParser\n",
    "import pandas as pd\n",
    "import os\n",
    "import patoolib\n",
    "import pickle\n",
    "\n",
    "# Abro el modelo entrenado\n",
    "lgbm  = pickle.load(open('lgbm.pkl','rb'))\n",
    "\n",
    "# lista de demos a procesar\n",
    "path = \"C:\\\\Users\\\\Matias\\\\Documents\\\\UDESA\\\\Tesis_maestria\\\\Atpt\\\\winProbDemos\"\n",
    "os.chdir(path)\n",
    "\n",
    "carpetas = []\n",
    "for file in os.listdir():\n",
    "    if \".rar\" in file:\n",
    "        carpetas += [file]\n",
    "    elif \".dem\" in file or \".json\" in file:\n",
    "        os.remove(file)\n",
    "        \n",
    "    \n",
    "# Ahora hay más archivos, puedo iterar sobre los nuevos\n",
    "for folder in carpetas:\n",
    "    # Extraigo la carpeta\n",
    "    patoolib.extract_archive(\"%s\" % folder, outdir=\"%s\" %path)\n",
    "    # La muevo a parsedDemos\n",
    "    #shutil.move(path + \"\\\\\" + folder, \"C:\\\\Users\\\\Matias\\\\Documents\\\\UDESA\\\\Tesis_maestria\\\\Atpt\\\\parsedDemos\")\n",
    "    \n",
    "    # Itero sobre los files y me fijo si son demo y no les cambié el nombre. Si no, les cambio el nombre\n",
    "    for demo in os.listdir():\n",
    "        for nombre in carpetas:\n",
    "            if (\".dem\" not in demo) or (demo[0] == \"x\"):\n",
    "                break\n",
    "        else:\n",
    "            os.rename(demo, \"x\" + folder.split(\"vs\")[0] + \"vs\" + demo.split(\"vs\")[1])\n",
    "\n",
    "# Agarro los nombres de las demos\n",
    "demos = []\n",
    "for file in os.listdir():\n",
    "    if \".dem\" in file:\n",
    "        demos += [file]\n",
    "\n",
    "### Itero el parser por cada demo\n",
    "round_state_df = pd.DataFrame()\n",
    "for demo in demos:\n",
    "    demo_parser = DemoParser(\n",
    "    demofile = \"%s\" % demo,\n",
    "    parse_rate=128, \n",
    "    buy_style=\"hltv\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Parse the demofile, output results to dictionary\n",
    "    df = demo_parser.parse(return_type=\"json\")\n",
    "\n",
    "    # Agarro los frames del comienzo de cada ronda\n",
    "    frames = []\n",
    "    for ronda in df[\"gameRounds\"]:\n",
    "        for f in ronda[\"frames\"]:\n",
    "            if f[\"seconds\"] <= 10.5 and f[\"seconds\"] >= 9.5:\n",
    "                frames.append(f)\n",
    "                break\n",
    "    mapa = df[\"mapName\"]\n",
    "    \n",
    "\n",
    "    # Genero los vectores para cada frame y los paso a un dataframe\n",
    "    states = []\n",
    "    for f in frames:\n",
    "        game_state = generate_vector_state(f, mapa)\n",
    "        states.append(game_state)\n",
    "    states = pd.DataFrame(states)\n",
    "    states[\"matchID\"] = (demo[:-4])\n",
    "    #states.index += 1\n",
    "    round_state_df = pd.concat([round_state_df, pd.DataFrame(states)])\n",
    "\n",
    "# YA NO NECESITO CALCULAR PROBABILIDAD DE GANAR LA RONDA\n",
    "#round_state_df_2 = round_state_df.drop(round_state_df.columns[len(round_state_df.columns)-1], axis=1)\n",
    "#round_state_df_2\n",
    "#round_state_df_2[\"bombPlanted\"] = round_state_df_2[\"bombPlanted\"].astype(\"category\")\n",
    "#round_state_df_2[\"bombsite\"] = round_state_df_2[\"bombsite\"].astype(\"category\")\n",
    "#round_state_df_2[\"mapName\"] = round_state_df_2[\"mapName\"].astype(\"category\")\n",
    "\n",
    "round_state_df.reset_index(inplace = True)\n",
    "\n",
    "#dfWinProbLgbm = pd.DataFrame(lgbm.predict_proba(pd.DataFrame(round_state_df_2)), columns = [\"tWinProbLgbm\", \"ctWinProbLgbm\"])\n",
    "#dfWinProbXgb = pd.DataFrame(xgb.predict_proba(pd.DataFrame(round_state_df_2)), columns = [\"tWinProbXgb\", \"ctWinProbXgb\"])\n",
    "#dfWinProbCb = pd.DataFrame(cb.predict_proba(pd.DataFrame(round_state_df_2)), columns = [\"tWinProbCb\", \"ctWinProbCb\"])\n",
    "#\n",
    "#round_state_df[[\"tWinProbLgbm\", \"ctWinProbLgbm\"]] = dfWinProbLgbm\n",
    "#round_state_df[[\"tWinProbXgb\", \"ctWinProbXgb\"]] = dfWinProbXgb\n",
    "#round_state_df[[\"tWinProbCb\", \"ctWinProbCb\"]] = dfWinProbCb\n",
    "\n",
    "with pd.ExcelWriter(\n",
    "    \"C:\\\\Users\\\\Matias\\\\Documents\\\\UDESA\\\\Tesis_maestria\\\\Atpt\\\\winProb.xlsx\",\n",
    "    mode = \"a\",\n",
    "    if_sheet_exists = \"overlay\"\n",
    ") as writer:\n",
    "    round_state_df.to_excel(writer, index = False, startrow = writer.sheets['Sheet1'].max_row, header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796bed78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(lgbm.predict_proba(pd.DataFrame(round_state_df_2)), columns = [\"tWinProb\", \"ctWinProb\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e399554",
   "metadata": {},
   "outputs": [],
   "source": [
    "round_state_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d37b0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
